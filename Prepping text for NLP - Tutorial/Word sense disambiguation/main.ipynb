{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation\n",
    "\n",
    "### Downloads\n",
    "You will need to download the wordnet data from NLTK data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sahithimv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sahithimv/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger') # for other languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses NLTK to tokenize the sentences and WordNet to obtain synsets (sets of synonyms with shared meanings) for each word. It then checks the definitions of the synsets to identify the relevant senses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence 1: I saw a bat flying in the night sky.\n",
      "Sense 1: cricket_bat.n.01 - Definition: the club used in playing cricket\n",
      "-------------------------\n",
      "Original Sentence 2: The baseball player swung the bat with precision.\n",
      "Sense 2: bat.v.01 - Definition: strike with, or as if with a baseball bat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence_1 = \"I saw a bat flying in the night sky.\"\n",
    "sentence_2 = \"The baseball player swung the bat with precision.\"\n",
    "\n",
    "tokenized_sentence_1 = word_tokenize(sentence_1.lower())\n",
    "tokenized_sentence_2 = word_tokenize(sentence_2.lower())\n",
    "\n",
    "sense_1 = lesk(tokenized_sentence_1, 'bat')\n",
    "sense_2 = lesk(tokenized_sentence_2, 'bat')\n",
    "\n",
    "print(f\"Original Sentence 1: {sentence_1}\")\n",
    "print(f\"Sense 1: {sense_1.name()} - Definition: {sense_1.definition()}\")\n",
    "print(\"-------------------------\")\n",
    "print(f\"Original Sentence 2: {sentence_2}\")\n",
    "print(f\"Sense 2: {sense_2.name()} - Definition: {sense_2.definition()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example uses the Lesk Algorithm to find overlap of words in dictionaries, to figure out different meanings of the same word.\n",
    "\n",
    "### Supporting different languages\n",
    "\n",
    "You will need to install the pywsd library to use the lesk algorithm to perform WSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywsd in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.2.5)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pywsd) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pywsd) (1.26.4)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pywsd) (2.2.0)\n",
      "Requirement already satisfied: wn==0.0.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pywsd) (0.0.23)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pywsd) (1.16.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk->pywsd) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk->pywsd) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk->pywsd) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk->pywsd) (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->pywsd) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->pywsd) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->pywsd) (2023.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pywsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this you can use the lesk algorithm to perform WSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Tomé una hoja de papel para tomar notas.\n",
      "No sense found for 'hoja' in the given context.\n",
      "-------------------------\n",
      "Sentence: El viento movía las hojas de los árboles.\n",
      "No sense found for 'hoja' in the given context.\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from pywsd.lesk import simple_lesk\n",
    "import nltk\n",
    "\n",
    "def perform_lesk(sentence, word, pos='n'):\n",
    "    try:\n",
    "        tokenized_sentence = nltk.word_tokenize(sentence.lower())\n",
    "        sense = simple_lesk(' '.join(tokenized_sentence), word, pos=pos)\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "        if sense:\n",
    "            print(f\"Sense: {sense.name()} - Definition: {sense.definition()}\")\n",
    "        else:\n",
    "            print(f\"No sense found for '{word}' in the given context.\")\n",
    "        print(\"-------------------------\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "sentence_3 = \"Tomé una hoja de papel para tomar notas.\"\n",
    "sentence_4 = \"El viento movía las hojas de los árboles.\"\n",
    "\n",
    "perform_lesk(sentence_3, 'hoja', pos='n')\n",
    "perform_lesk(sentence_4, 'hoja', pos='n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have also added code for handling exceptions when suitable lesk values, i.e. the entries for the words cannot be found. You might want to add this even for English text.\n",
    "\n",
    "Keep in mind this a very simple example. You might have to apply machine learning algorithms or other complex mechanisms for special use cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
