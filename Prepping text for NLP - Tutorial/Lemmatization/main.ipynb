{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "Lemmatization surpasses stemming by grouping words with similar meanings. For instance, it transforms 'better' to 'good.' The process involves part-of-speech (POS) tagging and utilizing NLTK's lemmatizer. The function below converts Treebank's tagging to WordNet's tagging convention. Additionally, it excludes stop words, such as prepositions, conjunctions, and articles, as they lack definitions in WordNet.\n",
    "\n",
    "#### Downloads required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sahithimv/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/sahithimv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sahithimv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sahithimv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger') #for POS tagging\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens: ['cats', 'are', 'chasing', 'mice', 'in', 'the', 'garden', ',', 'and', 'the', 'mice', 'are', 'running', 'away', '.']\n",
      "Filtered Tokens (after removing stop words): ['cats', 'chasing', 'mice', 'garden', 'mice', 'running', 'away']\n",
      "Lemmatized Words: ['cat', 'chasing', 'mouse', 'garden', 'mouse', 'running', 'away']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = \"Cats are chasing mice in the garden, and the mice are running away.\"\n",
    "tokens = word_tokenize(sentence.lower())  # Convert to lowercase for consistency\n",
    "stop_words = set(stopwords.words('english')) #<-- Plug in any other language here if you want\n",
    "filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "print(\"Original Tokens:\", tokens)\n",
    "print(\"Filtered Tokens (after removing stop words):\", filtered_tokens)\n",
    "print(\"Lemmatized Words:\", lemmatized_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
