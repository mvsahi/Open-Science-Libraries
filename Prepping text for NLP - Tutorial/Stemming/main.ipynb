{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Utilizing NLTK's SnowballStemmer to reduce words to their stems proves effective in consolidating various word variants to their root forms, rather than treating them as distinct entities.\n",
    "\n",
    "#### Downloads Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sahithimv/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use the SnowballStemmer from NLTK to stem a list of sample words. The stemmed versions of the words are then printed alongside their original forms. The output will show how the words are reduced to their root or stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: running | Stemmed: run\n",
      "Original: easily | Stemmed: easili\n",
      "Original: jumps | Stemmed: jump\n",
      "Original: quickly | Stemmed: quick\n",
      "Original: happily | Stemmed: happili\n",
      "Original: better | Stemmed: better\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "import nltk\n",
    "words_to_stem = [\"running\", \"easily\", \"jumps\", \"quickly\", \"happily\", \"better\"]\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_words = [stemmer.stem(word) for word in words_to_stem]\n",
    "for original, stemmed in zip(words_to_stem, stemmed_words):\n",
    "    print(f\"Original: {original} | Stemmed: {stemmed}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To stem words of different languages, plug the language in question into the SnowballStemmer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: corriendo | Stemmed: corr\n",
      "Original: rápidamente | Stemmed: rapid\n",
      "Original: saltos | Stemmed: salt\n",
      "Original: felizmente | Stemmed: feliz\n",
      "Original: mejor | Stemmed: mejor\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "import nltk\n",
    "\n",
    "spanish_words_to_stem = [\"corriendo\", \"rápidamente\", \"saltos\", \"felizmente\", \"mejor\"]\n",
    "spanish_stemmer = SnowballStemmer(\"spanish\")\n",
    "spanish_stemmed_words = [spanish_stemmer.stem(word) for word in spanish_words_to_stem]\n",
    "for original, stemmed in zip(spanish_words_to_stem, spanish_stemmed_words):\n",
    "    print(f\"Original: {original} | Stemmed: {stemmed}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
